= Restoring Rancher
:experimental:

This page outlines how to perform a restore with Rancher.

Follow the instructions from this page when:

* The running Rancher instance is at the same version as when the backup was made.
* The upstream (local) cluster is the same as where the backup was made.
[NOTE]
.Important
====

While restoring Rancher on the same setup, the operator will scale down the Rancher deployment when restore starts, and it will scale back up the deployment once restore completes. Rancher will be unavailable during the restore.
====

[TIP]
====

* Follow those steps to xref:migrate-rancher-to-new-cluster.adoc[migrate Rancher].
* If you need to restore Rancher to a previous version after an upgrade, see the xref:../../../getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster/rollbacks.adoc[rollback documentation].
====


== Create the Restore Custom Resource

A restore is performed by creating a Restore custom resource.

. In the upper left corner, click *â˜° > Cluster Management*.
. On the *Clusters* page, go to the `local` cluster and click *Explore*. The `local` cluster runs the Rancher server.
. In the left navigation bar, click menu:Rancher Backups[Restores].
. Click *Create*.
. Create the Restore with the form, or with YAML.  For creating the Restore resource using form, refer to the xref:../../../reference-guides/backup-restore-configuration/restore-configuration.adoc[configuration reference] and to the xref:../../../reference-guides/backup-restore-configuration/examples.adoc[examples.]
. For using the YAML editor, we can click menu:Create[Create from YAML]. Enter the Restore YAML.
+
[,yaml]
----
 apiVersion: resources.cattle.io/v1
 kind: Restore
 metadata:
   name: restore-migration
 spec:
   backupFilename: backup-b0450532-cee1-4aa1-a881-f5f48a007b1c-2020-09-15T07-27-09Z.tar.gz
   encryptionConfigSecretName: encryptionconfig
   storageLocation:
     s3:
       credentialSecretName: s3-creds
       credentialSecretNamespace: default
       bucketName: rancher-backups
       folder: rancher
       region: us-west-2
       endpoint: s3.us-west-2.amazonaws.com
----
+
For help configuring the Restore, refer to the xref:../../../reference-guides/backup-restore-configuration/restore-configuration.adoc[configuration reference] and to the xref:../../../reference-guides/backup-restore-configuration/examples.adoc[examples.]

. Click *Create*.

*Result:* The rancher-operator scales down the rancher deployment during restore, and scales it back up once the restore completes. The resources are restored in this order:

. Custom Resource Definitions (CRDs)
. Cluster-scoped resources
. Namespaced resources

== Logs

To check how the restore is progressing, you can check the logs of the operator. Run this command to follow the logs:

----
kubectl logs -n cattle-resources-system -l app.kubernetes.io/name=rancher-backup -f
----

== Cleanup

If you created the restore resource with kubectl, remove the resource to prevent a naming conflict with future restores.

== Known Issues

In some cases, after restoring the backup, Rancher logs will show errors similar to the following:

----
2021/10/05 21:30:45 [ERROR] error syncing 'c-89d82/m-4067aa68dd78': handler rke-worker-upgrader: clusters.management.cattle.io "c-89d82" not found, requeuing
----

This happens because one of the resources that was just restored has finalizers, but the related resources have been deleted so the handler cannot find it.

To eliminate the errors, we need to find and delete the resource that causes the error. See more information https://github.com/rancher/rancher/issues/35050#issuecomment-937968556[here]
